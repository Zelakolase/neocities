[{
        "title": "Anonybox",
        "link": "https://github.com/Zelakolase/Anonybox",
        "description": "There exists multiple privacy-focused messaging and mailing applications, such as Signal or Telegram. Unfortunately, there is not much development or interest in building decentralized messaging and mailing apps while using E2EE, examples are limited to Zeronet, for instance. Anonybox serves as the simplest decentralized mail service while using quantum-resistant encryption algorithms for both network communication and server data storage. It is a terminal-based server and client programs where you can host your own server and communicate with other mail servers, or connect as a client to an existing mail server. The information that can be sent is text only, no attachments or other features. Some might consider it as a disadvantage, but Anonybox is not intended for public use. Anonybox benefits journalists and those who want to share highly secret text in a decentralized network, far from ISP or government monitoring systems, which involve packet interception techniques. This is especially benefical for those who live in countries with high government censorship and interception, such as Turkey, Egypt, or Syria. Anonybox uses AES-ECB-PKCS5 Algorithm for symmetric encryption and decryption, and uses Diffie-Hellman Key Exchange Algorithm for the handshake between the server and client, to ensure sharing a secret key without actually revealing it to the public network. Anonybox focuses on software minimalism and code quality, in order to allow other developers to customize Anonybox to their liking, and make other versions of it. Anonybox is built from scratch, even the DBMS, and an internal naming server in order to replace conventional DNS server for Anonybox server domain resolve. The decentralization of Anonybox comes from the ability to deploy personal servers. Just like the internet in the early days, you can register to an internal naming server, or connecting directly to the destination server, without having to connect to a central server."
    },
    {
        "title": "SimplyWebServer",
        "link": "https://github.com/Zelakolase/SimplyWebServer",
        "description": "Very few minimal dynamic web server projects exist. Instead, the market uses popular web servers which are proven to be prone to multiple security vulnerabilities. Moreover, the local configuration of these popular web servers is not beginnerfriendly. SimplyWebServer tries to be as simple as possible while providing all necessary functions for developers (eg. SSL/TLS, Static File Optimization, etc..). SimplyWebServer is mainly targeted for small-sized to medium-sized projects. For example, internal systems, graduation projects, etc.. . The project allows them to peek through the internal server source code while understanding it, allowing them to modify any basic function of the web server to their usecase. Furthermore, you can compile your web application to a binary image using GraalVM. This allows your web application to be deployed on any target operating system easily, depending only on the C library of the system (effictively the core system calls). SimplyWebServer is not just another project for those who like minimal codebases, it is also a perfect learning opportunity for any college student or a computer enthusiast, to learn how SimplyWebServer understands and parses HTTP requests from clients. The student learns every detail, from TCP connection details, to buffered reading and writing on the TCP socket, to how to deserialize the HTTP request to an object in memory with properties that you can work with. Furthermore, the student learns how to implement multi-threading in a safe way by limiting the number of active threads and setting a timeout for any request that wants to be processed while the active threads equal to the maximum number of threads allowed by SimplyWebServer. In addition, LOGJAM and Client Renegotiation attacks are mitigated by modifying the JDK properties in runtime. As previously said, it does not only secure SimplyWebServer-built web applications, but it is a learning opportunity for others instead of searching about a mitigation by themselves for hours. Since SimplyWebServer is made from scratch, every library and file is only dependent on core libraries, adding to the security and compatibility of the project. Additionally, the usage of advanced data structures serves as an example of realworld application, not just a proof of concept or as an example in a Udemy course."
    },
    {
        "title": "Simuconomy",
        "link": "https://github.com/Zelakolase/Simuconomy",
        "description": "The dynamics of the free market economic model, and its relation with consumer behaviour has opened a new and interesting field of research. This field involves behavioural economics, econometrics, computational economics, and computer science. Advances in this field of research leads in more accurate real-world economic, financial, and monetary decisions. Previous research in this field has indicated that there might be an optimal tax formula for income and corporate, such formulas are claimed to outperform the Saez formula of optimal labour income tax1 . Unfortunately, most of these models are computationally extensive due to the usage of artifical intelligence, and do not make proper abstractions of real-world economies. Simuconomy is one of the few agent-based models that does not use artificial intelligence. The author believes that self-correcting deterministic models are sufficient to replace artificial-intelligence-related methods. Simuconomy uses genetic algorithms to correct for market shock behaviour and optimize the economic stability on a computational level. One of the innaccuracies that Simuconomy shares with other models is that all agents have some sort of production power. This is inaccurate since real-world agent production is determined by the corporation general productivity. Therefore, this model is only true if all agents are freelancers. However, I am planning to actively research methods to implement current hierarichal economic model in order to get more accurate results, and make proper abstractions to balance between computational irreducibility and real-world accuracy. In general, designing economic simulation models and analyzing free market behaviour directs us towards more accurate economic decisions. For example, taxation on inheritence, monetary policies and Universal Basic Income, optimal price control policies, and more. Simuconomy relies on genetic crossover and variability of agents’ genetic code, in order to stabilize the entirety of the economic system by the concept of ‘Survival of the fittest’. Every agent produces and consumes some units of food, and tries to optimize production to consumption ratio on an individual level."
    },
    {
        "title": "SparkDB",
        "link": "https://github.com/NaDeSys/SparkDB",
        "description": "For a long time, SQL has dominated the database management field in Computer Science and Engineering. As applications deal with more data and higher demand over time, new solutions were needed to decrease the latency of reading and writing on the database. This demand created a supply of memory-cache databases such as ‘Redis’. Furthermore, multiple DBMSes were developed to tackle certain problems (eg. PostgresSQL, MongoDB, MariaDB, etc..). A key disadvantage that was not addressed was the abstractness of DBMSes. This led to a new demand of modular and abstract DBMS that can be shaped for nearly any use case. This simplifies the process of choosing the “right” DBMS for your application, and allows for MVP development at low time cost. That was a key issue that SparkDB is trying to solve. SparkDB is a bloatware-free DBMS, no unused core features. SparkDB is a merely advanced method to manipulate CSV files, which is an extremely powerful tool for data analysis and beyond. SparkDB is a local object in Java that allows you to navigate through the CSV structure. It is not a library, but a free-to-use one Java code file that you can copy and paste in your project, which is the simplest integration process possible. I have written a guide in the code repository explaining how to use it, so I will not redo it here. Instead, I will focus on the inner workings of SparkDB and how it can be scaled for nearly every use case. Every CSV has two main things: column titles, and values. SparkDB is essentially a highly optimized Hash Map with a key and value, such that the key is the column title, and the value is an array of values under the column title. It allows for data duplication and parsing from AES-encrypted CSV files. Then, you can hypothesize that every table is essentially a CSV file, and you can build JSON-to-CSV structure code, TCP interface, or any other modification by yourself. You can also shard data based on a prefix/suffix and use SparkDB as the navigator. In short, SparkDB is the core, building block for your customized use case, either a memory cache database, or a simple write-to-disk relational database. One big advantage for SparkDB over Redis is that you are not limited to pairs of information, like a conventional hashmap. Instead, SparkDB takes it a step further, and allows you to have unlimited columns per table. Maximum rows for a single table is around 2.15 billion. In order to get values, modify, or add data to a SparkDB object, you use function calls, not SQL-like queries. This is a much simpler and minimal process. By calling .toString() function, you translate the modified SparkDB memory structure to a CSV form that you can store into permanent disk. Just like SQL-based solutions, you can make relationships between tables via a key, that you get to choose. The main difference is that you code relationships yourself, giving developers the full control over database and code behaviour."
    },
    {
        "title": "GCKit",
        "link": "https://github.com/Zelakolase/GCKit",
        "description": "Multiple algorithms have attempted to tackle a difficult problem, that is, detection of clusters in a network ‘hereinafter called graph’. For the protein-protein interaction network case, network nodes are proteins and connections ‘hereinafter called edges’ are the interaction evidence and strength between each protein. Unfortuantely, using unsupervised learning algorithms for cluster and community detection is not intuitive, since proteins need to be plotted on a 2D chart. Therefore, a walk-based algorithm is needed to efficiently tackle this issue. Multiple algorithms are currently used in the pharmachological field, such as Markov-Clustering algorithm, the louvain method, Infomap, k-means, and CliXO. The only satisfiable high-performing algorithm is CliXO. A new algorithm is needed to tackle this issue from scratch. Progress in cluster detection for protein-protein interaction networks opens a huge opportunity in accurately categorizing diseases by the chain of protein irregularties and reactions that caused the disease, and the development of new drugs that can save billions of lives worldwide and solve chronic diseases’ root causes. I was introduced to the problem by Dr. Mahmoud Elbatreek in the faculty of pharmacy, Zagazig University during my work in the university and the fruitful discussions that we had on the integration of mathematical and computational sciences with pharmachology. Proteins are divided into 3 categories, heads, normal proteins, and transition proteins. Head proteins can be categorized into a single cluster, transition proteins cannot be categorized into a single cluster, and normal proteins are halfway through the categorization. Clusters are heirarchial, where for a certain cluster, there is a head node ‘master’ and normal nodes ‘members, or slaves’. A protein can join multiple clusters at once (including transition proteins). We concluded that GCKit outperformed every popular algorithm except CliXO with a small margin, all of the generated clusters were significantly enriched with a p-value < 1.0e-16 (for Amyotrophic Lateral Sclerosis). This is a promising result for disease modulation and further pharamchological discoveries. In addition, we try to follow ISO-25010 for code quality in order to allow developers to customize our work to their use cases, and to achieve high maintainability."
    }
]